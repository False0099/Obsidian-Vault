我们的多元回归分析是盐究随机变量之间相关关系的一种统计方法，通过对变量实际观测的分析，计算，建立一个变量与另一组变量的定量关系。**可以用于我们的预测与分析**。

## 线性回归
我们的线性回归，就是认为我们的**结果与我们的变量之间是一个线性的关系**，例如我们的 $y=\beta_{0}+\beta_{1}x_{1}+\dots+\beta_{n}x_{n}$ 就是一个 n 元回归模型。

我们的线性回归的步骤如下所示：
1. 由观测值确定参数 $\beta_{0},\beta_{1},\dots \beta_{n}$ 的估计值 $b_{0},b_{1},\dots b_{n}$
2. 对线性关系，自变量的显著性进行统计检验
3. 利用回归方程进行预测。

### 最小二乘估计
我们对我们的 $y,x_{1},,..x_{n}$ 进行 n 次抽样，得到 n 组数据，我们这个时候，对于我们收集到的数据，我们记
$$X=\left[\begin{array}{c}
1 & x_{11} &x_{12}\dots x_{1n} \\
1 & x_{21} &x_{22}\dots x_{2n} \\ 
1 & x_{31} &x_{32}\dots x_{3n} \\ 
1 & x_{n1} &x_{n2}\dots x_{nn} \\
\end{array}\right]
$$

我们记$$
X=\left[\begin{array}{c}
y_{1}  \\
y_{2} \\ 
y_{3} \\ 
y_{4} \\
\end{array}\right]
$$

最后，我们的上述的条件就可以表示为:
$Y=X\beta$

我们应该选取合适的 $bj$,使得当我们的 $\beta=b$ 的时候，我们的误差平方和：
$Q=\sum_{i=1}^{n}d^2=\sum(y_{i}-\beta_{0}-\beta_{1}x_{1}\dots)^2$ 最小

为此，我们令我们的  $\frac{\partial Q}{\partial \beta_{j}}=0$。由此，我们可以得到，我们的 $$\begin{array}{C}
\frac{\partial Q}{\partial \beta_{0}}=-2\sum_{i=1}^{n}(y_{i}-\beta_{0}-\beta_{1}x_{i_{1}}-\dots-\beta_{m}x_{\mathrm{Im}})=0 \\
\frac{\partial Q}{\partial \beta_{j}}=-2\sum_{i=1}^{n}(y_{i}-\beta_{0}-\beta_{1}x_{i_{1}}-\dots-\beta_{m}x_{\mathrm{Im}})x_{ij}=0
\end{array}$$

经过我们的整理后，我们可以转换为下面的正规方程组：
$X^{T}X\beta=X^{T}Y$，显然，当我们的 $X$ 列满秩的时候，我们的 $X^{T}X$ 是一个可逆方针，我们的解就有：
$\beta=(X^{T}X)^{-1}X^{T}Y$。这样，我们就可以**求出我们的对应的各个参数的估计**。

### 统计检验：
我们的前面都是在假定我们的随机变量和我们的最终结果之间存在一个线性关系的情况下才建立的线性防尘，我们就需要通过我们的假设检验来**检查我们是不是所有的变量都对我们的结果有影响**。

第一步：我们对我们的总平方和（$SST$）进行分解，我们就有 $SST=SSE+SSR$,其中我们的 $SSE$ 是 $\sum_{i=1}^{n}(y_{i}-y_{i}^{'})^{2}$ 叫做我们的残差平方和。其中沃恩的 $y_{i}^{'}$ 表示我们的**估计结果**。

我们的 $SST=\sum(y_{i}-y_{i}^{1})$ 其中我们的内部表示我们的**统计平均值**。我们的 $SSR$ 就显然，应该是我们的回归平方和，反应**自变量对 y 的影响**。

当我们的假设成立时，我们的 $SSR$ 和我们的 $SSE$ 应该满足下面的关系：$F=\dfrac{\dfrac{SSR}{m}}{\dfrac{SSE}{(n-m-1)}}$ 应该符合我们的 $F$ 分布。


