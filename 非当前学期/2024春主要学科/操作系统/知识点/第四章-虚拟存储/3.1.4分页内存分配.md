分区式（连续）存储管理最大的缺点是碎片问题严重，内存利用率低。究其原因，主要在于连续分配的限制，即它要求每个作用在内存中必须占一个连续的分区。**如果允许将一个进程分散地装入到许多不相邻的分区中，便可充分地利用内存，而无需再进行“紧凑”**。基于这一思想，产生了“非连续分配方式”，或者称为“离散分配方式”。

## 页式内存管理
我们的页式内存管理，利用的想法就是把我们的原本的内容划分为若干个小块，我们满足**小块内的地址是连续的**，我们的每一块之间不一定是连续的。同时，为了实现我们的这一个内容，我们还需要**对我们的小块进行编址，编号**。

于是，我们就诞生了我们的页式内存管理：操作系统**以页框为单位为各个进程分配内存空间**。系统自动地将作业的地址空间分页，将系统的主存空间分块，页与块等大小，在作业运行时，一次性把作业的全部页面装入内存，**各个页所占的内存块可以不连续，也不必按先后顺序，可以放到不相邻的各个页框中**。
### 数据结构
而我们在我们的页式内存管理中，同样也需要一种**数据结构**，能够让我们快速的获得我们需要的信息，这里我们为了能够获得我们的高个儿部分的信息，我们就需要指导下面的内容：
1. 我们的每一个**页号**对应的**块号**是多少，也就是维护我们的**逻辑地址**到我们的实际地址的一个映射。我们对于我们的每一个进程都需要维护一个属于**这一个进程的页表**。
![[Pasted image 20240612170254.png]]


### 地址映射算法：
为了能够实现我们的地址映射，我们应该采用我们的下面的算法：我们每一次首先将我们的**逻辑地址**分为两个部分，一个部分是我们的**页内地址**，另一个是我们的**页号**。我们将我们的**页号**拿去我们的页表中进行查询，如果查询到了对应的快好，这个快好就作为我们的**物理地址的前半部分**，然后直接和我们的逻辑地址的页内偏移进行拼接即可。
![[Pasted image 20240612170536.png]]

### 速度优化
我们注意到，我们在上述的过程中，我们的每一次逻辑地址到我们的实际地址的转换，都需要进行我们的两次访存，我们先去查询我们的页表，第二次去查询我们的真正的物理地址。

我们考虑能否通过我们的一些方法来优化我们的查询，我们注意到，我们如果能够将我们的第一次访存的平均次数减少，那么我们就能够提高我们的速度。

于是，我们可以考虑使用一个**存储在内存中的快表**，也可以理解为我们的 Cache, 我们先去检查我们的快表中是否存在我们的对应的内存地址，如果存在我们就不需要去访问页表，我们直接去访问我们的内存即可。

![[Pasted image 20240612171645.png]]

### 内存优化：
我们注意到，如果我们采用原来的方法的话，我们的可能达到的最大内存是：$min(id_{1},id_{2})\times len(id_{1}+id_{2})$,其中我们的 $id_{1}$ 表示我们的页号，我们的 $id_{2}$ 表示我们的块号。

我们的思路是：将我们的页表分为两个部分，这样，我们就可以将我们的长度直接减半，这个时候，我们就有：
![[Pasted image 20240612171928.png]]


此时我们的地址转换如下所示：
![[Pasted image 20240612171950.png]]

## 页式分配：
我们的页式分配因为是离散的，所以我们只需要管理我们的哪些页是空闲的，我们有多少个页是空闲的即可。于是我们就可以利用我们的**位图**，类似于我们的 `bitset` 来优化哦我们的计算。
![[Pasted image 20240612172116.png]]


计算一个作业所需要的总块数 N  
查位示图，看看是否还有N个空闲块  
如果有足够的空闲块，则页表长度设为N，可填入PCB中；申请页表区，把页表始址填入PCB  
依次分配N个空闲块，将块号和页号填入页表  
修改位示图

